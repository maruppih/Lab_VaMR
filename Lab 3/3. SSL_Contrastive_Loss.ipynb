{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WlzRGSguPAX"
      },
      "source": [
        "# Contrastive Loss (SimCLR)\n",
        "\n",
        "\n",
        "In this session, we are going to implement the SimCLR loss function (https://arxiv.org/abs/2002.05709).\n",
        "\n",
        "This follows the InfoNCE loss, i.e., uses two different augmented versions of the same image as positive pair and the other images in the batch as negative samples, and the batch construction of the N-pair-mc loss.\n",
        "\n",
        "prima si calcola in maniera matriciale le feature, poi matrice di similitudine\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con lo scorso lab abbiamo ottenuto y e y', quello che fa SimCLR è aggiungere g() ovvero un projector. Quindi non avremo l'Identity() finale, ma un MLP. Tipicamente MLP ha questa forma: Linear, BatchNorm, ReLU, Linear, BatchNorm.\n",
        "\n",
        "Generare MLP da cui escono le proiezioni delle uscite della backbone. Su queste z e z' andremo a fare la Contrastive Loss.\n",
        "Andremo a fare poi forward e backprop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xaJjICcLhd2B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.io import read_image\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MORD6VylNFWd"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, data, targets = None, transform=None, target_transform=None): # valori di default\n",
        "        self.imgs = data\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.imgs[idx]\n",
        "        if isinstance(img, str):\n",
        "          image = read_image(img)\n",
        "        else:\n",
        "          image = Image.fromarray(img.astype('uint8'), 'RGB')\n",
        "        if self.transform: # arriva qui con una PIL image\n",
        "            image1 = self.transform(image) # fa due trasformazioni\n",
        "            image2 = self.transform(image)\n",
        "        else:\n",
        "            image1 = image\n",
        "            image2 = image\n",
        "        return image1, image2\n",
        "\n",
        "\n",
        "class Identity(torch.nn.Module):\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "\n",
        "\n",
        "class SiameseNet(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.encoder1 = backbone\n",
        "        self.encoder1.fc = Identity()\n",
        "\n",
        "        self.encoder2 = backbone\n",
        "        self.encoder2.fc = Identity()\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2, return_dict = True):\n",
        "        x1 = self.encoder1(x1)\n",
        "        x2 = self.encoder2(x2)\n",
        "        return torch.cat((x1, x2), dim = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xOQLKK59Nt3-"
      },
      "outputs": [],
      "source": [
        "backbone = models.resnet18()\n",
        "\n",
        "backbone.fc = nn.Identity()\n",
        "\n",
        "model = SiameseNet(backbone)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Versione 1 (più efficiente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ABbKJPlwuOb0"
      },
      "outputs": [],
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.07):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, features):\n",
        "\n",
        "        # torch.cat((x1, x2), dim=0) # copiare output della siamese\n",
        "        # normalize features to later compute cosine distance/similarity btw them\n",
        "        features = F.normalize(features, dim=1)\n",
        "        # compute the similarity matrix btw features\n",
        "        # (consider that feature are normalized! so the cosine similarity is ...)\n",
        "\n",
        "        # Calcola la matrice di similarità coseno\n",
        "        similarity_matrix = torch.matmul(features, features.T) # prodotto matricale element wise # spesso compare come feature @ features.T\n",
        "\n",
        "        # andiamo a costruire un array di label di numeri da 0 a 63, fa un arange da 0 a bs, va a prendersi idx\n",
        "\n",
        "        labels = torch.cat([torch.arange(features.shape[0]//2) for i in range(2)], dim=0) # print\n",
        "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float() # la unsqueeze aumenta la dimensione di un tensore, qui fa 128,1, modifica la shape # print\n",
        "\n",
        "        mask = torch.eye(labels.shape[0], dtype = torch.bool)\n",
        "        labels = labels[~mask].view(labels.shape[0], -1)\n",
        "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
        "        # assert similarity_matrix.shape == labels.shape\n",
        "\n",
        "        # select and combine multiple positives\n",
        "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
        "\n",
        "        # select only the negatives\n",
        "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1) # che effetto ha view? è simile al re-shape, si fa a riforzare la shape di un tensore\n",
        "        # questo reshape che dimensione ha? 8,\n",
        "\n",
        "\n",
        "        #print(similarity_matrix)\n",
        "        #print(similarity_matrix[:, 0].shape)\n",
        "\n",
        "        # moltiplicazione element wise (elemento dim 512)\n",
        "\n",
        "        # alla positive do una ground truth (0)\n",
        "        # sim_mat\n",
        "        # for\n",
        "        # si prende la positive pair e la metto in posizione 0, tutti gli altri (2n-1) li metto dalla posizione 1 alla 2n, qui ho tutti i negative\n",
        "        # i logit sono gli 0, gli altri sono gli elementi bassi, 0 alti\n",
        "\n",
        "\n",
        "        # create the logits tensor where:\n",
        "        #   - in the first position there is the similarity of the positive pair\n",
        "        #   - in the other 2N-1 positions there are the similarity w negatives\n",
        "        # the shape of the tensor need to be 2Nx2N-1, with N is the batch size\n",
        "        logits = torch.cat([positives, negatives], dim = 1)\n",
        "        logits = logits / self.temperature\n",
        "\n",
        "\n",
        "        # to compute the contrastive loss using the CE loss, we just need to\n",
        "        # specify where is the similarity of the positive pair in the logits tensor\n",
        "        # since we put in the first position we create a gt of all zeros\n",
        "        # N.B.: this is just one of the possible implementation!\n",
        "        gt = torch.zeros(logits.shape[0], dtype=torch.long) # ground truth\n",
        "        return self.criterion(logits, gt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In SimCLR abbiamo la temperature che è un iperparametro.\n",
        "Per ogni feature andiamo a calcolarci la similitudine in maniera matriciale. Prima le normalizziamo e poi si fa la matrice di similitudine (che è la moltiplicazione element wise delle features tra di loro). Una volta fatto questo, si va distinguere la positive pair rispetto alla negative pair. infine si va a calcolare la cross-entropy loss della positive rispetto ai negative. Per farlo, possiamo fare così: una volta calcolate le similitudini delle positive e delle negative pair, alla positive diamo un gt, una label, che è 0. Conviene fare così: una volta calcolata la matrice di similitudine, ci conviene mettere, dato ogni elemento (quindi con un for), per ogni elemento andiamo a prendere la positive pair e andiamo a metterla in un'altra matrice in prima posizione 0. Tutti gli altri, che sono le 2N - 1, li mettete dalla posizione 1 fino alla 2N. Lo facciamo per ogni elemento.\n",
        "\n",
        "Alla fine, per calcolare la loss finale, facciamo un cross-entropy. (ha un tensore, logits) Nella prima posizione mettiamo la similitudine della positive pair e nelle altre 2N-1 mettere le similitudini con i negative. Alla fine avremo una matrice che ha come dimensioni 2N x 2N - 1. Quindi nella matrice dei logits tolgo l'elemento stesso, metto in prima posizione l'elemento 0 e dopo metto tutti gli altri. Il risultato è che logits sarà una matrice 2N x 2N - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "VERSIONE 2 - BASATA SU TENSORI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tMbJhvs4zNs4"
      },
      "outputs": [],
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.07):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, features): # IMPLEMENTAZIONE PIù SEMPLICE\n",
        "        features = F.normalize(features, dim=1) # dimensione 2n x 512 delle features\n",
        "        similarity_matrix = torch.matmul(features, features.T) # prodotto matricale element wise # spesso compare come feature @ features.T\n",
        "\n",
        "        print(similarity_matrix[0])\n",
        "\n",
        "        batch_size = features.shape[0]//2\n",
        "        logits = torch.zeros(2*batch_size, 2*batch_size-1)\n",
        "\n",
        "        # nella prima metà del batch = positive + 64, negative - 64\n",
        "\n",
        "        for idx, val in enumerate(similarity_matrix): # id elemento con cui stiamo facendo\n",
        "          row = torch.zeros(2*batch_size-1) # row è di 0\n",
        "\n",
        "          pos_idx = idx + batch_size if idx < batch_size else idx - batch_size # per trovare l'indice del positive sample bisogna fare idx + batch size nel caso in cui l'indice sia pi+ piccolo del batch size # nell'altro caso io farò idx - bs\n",
        "          # metto nella prima posizione di row\n",
        "          row[0] = val[pos_idx]\n",
        "          row[1:] = torch.tensor([v for i, v in enumerate(val) if i!=idx and i!=pos_idx]) # list of compression\n",
        "          # prendo 126 elementi che sono in val che non sono nè idx nè pos_idx\n",
        "\n",
        "          '''\n",
        "          STESSA COSA DI FARE:\n",
        "\n",
        "          negatives = []\n",
        "          for i, v in enumerate(val):\n",
        "            if i!=idx and i! = pos_idx:\n",
        "              negatives.append(v)\n",
        "            row[1:] = torch.tensor(negatives)\n",
        "          '''\n",
        "\n",
        "          logits[idx] = row\n",
        "\n",
        "        logits = logits / self.temperature # formula\n",
        "\n",
        "        gt = torch.zeros(logits.shape[0], dtype=torch.long) # positive in first position # cross entropy\n",
        "\n",
        "        return self.criterion(logits, gt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agvz2chP0Ndg"
      },
      "source": [
        "Let's now use the Dataset which creates the two augmented views for each image and the Siamese Network from the past lab session [1](https://colab.research.google.com/drive/1NJwAFbRiD4MdwWf__6P2Lm0xYk_DNdVu?usp=sharing) and [2](https://colab.research.google.com/drive/1AMkh0q8L5nJScx7v6cMWoK336zqOqDY6?usp=sharing) and create a training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbI4vhv154O-",
        "outputId": "cfdd160f-c381-40ac-9ac2-ec5f8d485ddb"
      },
      "outputs": [],
      "source": [
        "data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True) # dataset\n",
        "\n",
        "color_jitter = transforms.ColorJitter(0.8, 0.8, 0.8, 0.2) # si distorce il colore con una certa probabilità tutti i canali\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.RandomResizedCrop(size=32),\n",
        "                                  transforms.RandomHorizontalFlip(),\n",
        "                                  transforms.RandomApply([color_jitter], p=0.8),\n",
        "                                  transforms.RandomGrayscale(p=0.2),\n",
        "                                  transforms.GaussianBlur(kernel_size=int(0.1 * 32)),\n",
        "                                  transforms.ToTensor()])\n",
        "\n",
        "trainset = CustomImageDataset(data.data, transform = transform)\n",
        "dataloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "model = SiameseNet(models.resnet18())\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = ContrastiveLoss()\n",
        "\n",
        "for idx, data in enumerate(dataloader):\n",
        "    view1, view2 = data\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    features = model(view1, view2)\n",
        "    loss = criterion(features)\n",
        "    # tensore su cui fare la bp\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"batch {idx} loss {loss.item()}\")\n",
        "    print()\n",
        "\n",
        "    if idx == 3:\n",
        "        break\n",
        "\n",
        "# sistemare"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
